# sbertest
Обучение модели.

Для решения задачи классификации я применил классификатор логистической регрессии, веса токенов назначал при помощи алгоритма tfidf , а сет для тренировочных данных собрал с
помощью Wordstat . Далее подробно аргументирую свой выбор.

На вход телеграм бот, как правило, получает небольшую фразу скорее всего содержащую ключевые слова запроса , имеющие в дальнейшем решающий фактор для определения нужного класса. Значит и тренировочный набор данных должен
содержать подобные документы . Наиболее релевантным материалом для обучения модели мне показались запросы пользователей в поисковике Яндекса.

Сервис Wordstat имеет широкие возможности для фильтрации получаемых данных, но в формате тестового задания я ограничился стандартными настройками. 
Основным фактором при сборе тренировочных данных стала частота запросов . В моём сете документ копировался в зависимости от кол ва запросов , делённых на 10. 
К примеру, документ с содержанием ит ипотека появится в сете 1910 раз.

![Снимок экрана 2022-07-25 152146](https://user-images.githubusercontent.com/98345179/180776428-81bd7392-b8f3-4b00-bdf8-6a1fb29d0e64.png)

Зачем делать копии документов в тренировочном
сете?

Для взвешивания токенов я использую механизм
tfidf , или tf умножить на idf . Коротко, tf показатель
важности слова в документе , idf показатель
важности слова относительно коллекции
документов . То есть чем больше документов в
коллекции с определённым словом, тем значимей
будет это слово для определённой метки класса.
Таким образом соблюдается пропорция: чем
частотней запрос (а значит фраза важней для
определённого класса), тем больше idf его слов, тем
больше конечный вес слов для класса ( tf x idf).


Для 17
ти классов у меня получилось чуть больше 100 тысяч документов. Данные по классам сильно разбалансированы (с
этим вряд ли можно что либо сделать не меняя сути подхода к решению задачи). Из всех данных я удалил не информативные
предлоги и слово «ипотека» оно будет негативно влиять при дисбалансе классов в пользу определения наиболее
представленных классов. Так же я лемматизировал токены на небольшом сете тестовых данных лемматизация дала
прирост точности в 20%




Реализация бота @testsber_nb_bot.

Для увеличения точности предсказания метки для единичной фразы, я решил
воспользоваться API « Букварикс ».

Когда классификатор предсказывает метку
для единичной фразы , велика цена ошибки… Поэтому я решил предсказывать
класс не одного документа, а для целого тестового набора документов . Его я получаю при передаче запроса (вопрос
посетителя из чата с телеграмм ботом) в выше упомянутое api . Другими словами, на выходе мы получаем коллегиальное
решение по фразе посетителя чата вместо единичного.

![2](https://user-images.githubusercontent.com/98345179/180777057-647493f3-53c8-4527-8970-0a5a8cb3822a.png)

Конечно, есть свои нюансы.
Букварикс выдаёт не
более 250 ключевых фраз (то есть документов
тестовой коллекции), что не очень много. С другой
стороны, большое кол во данных дало бы задержку
по времени ответа бота так как тестовый набор
перед предсказанием так же лемматизируется

При
низкочастотном запросе посетителя чата,
Букварикс может не выдать ничего. Тогда придётся
работать с единичной фразой пользователя . К тому
же довольно часто может вводится «смежный»
запрос. К примеру запрос «ипотека для молодой
семьи» можно отнести как к «молодёжной» так и
«семейной» ипотеке .

На этот случай я предусмотрел следующий сценарий.

![3](https://user-images.githubusercontent.com/98345179/180777195-0057a7d9-1df4-42ce-ac03-bccb3027aba7.png)

При реализации бота, я предусмотрел то, что
посетителю чата будут дополнительно предложены
две кнопки с теми ипотечными продуктами которые
наиболее вероятны после основного предложения.
Нажав одну из дополнительных кнопок, посетитель
получит информацию идентичную основному
предложению.

Этих два дополнительных ипотечных продукта
выбираются на основе вероятности. То есть, в
отсортированном по убыванию массиве вышедшем
из классификатора, они располагаются на 2ой и 3ей
позициях
